{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be08fe4c-d661-44d3-b106-03328643f2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Year      Month  Wind  Condition  Day        Time  Temperature  \\\n",
      "0    2013      April   6.0        1.0    1  650.000000    30.375000   \n",
      "1    2013     August   5.0        2.0    5  650.000000    29.208333   \n",
      "2    2013   December  18.0        2.0    2  650.000000    26.625000   \n",
      "3    2013   February   6.0        1.0    4  652.173913    27.434783   \n",
      "4    2013    January   1.0        2.0   14  650.000000    25.875000   \n",
      "..    ...        ...   ...        ...  ...         ...          ...   \n",
      "124  2023      March  17.0        1.0    6  650.000000    26.875000   \n",
      "125  2023        May   6.0        1.0    1  650.000000    31.166667   \n",
      "126  2023   November   5.0        1.0    6  632.600000    30.280000   \n",
      "127  2023    October  12.0        2.0    2  636.185185    28.444444   \n",
      "128  2023  September  12.0        5.0    4  649.440000    27.320000   \n",
      "\n",
      "     Dew Point   Humidity  Wind Speed  Wind Gust     Pressure  Precip.  \n",
      "0    22.208333  62.041667   12.750000   0.000000  1009.076250      0.0  \n",
      "1    24.208333  75.166667   13.916667   1.833333  1005.876667      0.0  \n",
      "2    24.208333  87.500000    5.083333   0.000000  1009.201250      0.0  \n",
      "3    20.130435  65.434783   13.565217   0.000000  1012.891739      0.0  \n",
      "4    21.458333  72.500000   14.083333   1.708333  1008.079167      0.0  \n",
      "..         ...        ...         ...        ...          ...      ...  \n",
      "124  18.208333  59.791667    8.750000   0.000000  1012.732500      0.0  \n",
      "125  24.250000  67.458333   10.416667   2.916667  1006.540417      0.0  \n",
      "126  25.000000  73.880000    8.400000   0.000000  1008.084000      0.0  \n",
      "127  26.259259  88.111111   14.444444   0.000000  1005.732593      0.0  \n",
      "128  25.920000  92.240000   10.960000   0.000000  1003.339600      0.0  \n",
      "\n",
      "[129 rows x 13 columns]\n",
      "['January' 'February' 'March' 'April' 'May' 'June' 'July' 'August'\n",
      " 'September' 'October' 'November' 'December']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "water_quality_df = pd.read_csv('Overall-dataset-llda(not_cleaned).csv')\n",
    "weather_df = pd.read_csv('New_Weather.csv')\n",
    "\n",
    "water_quality_df['Phytoplankton (cells/ml)'] = water_quality_df['Phytoplankton (cells/ml)'].str.replace(',', '')\n",
    "\n",
    "water_quality_df['Month'] = water_quality_df['Month'].astype(str)\n",
    "water_quality_df.replace('-', np.nan, inplace=True)\n",
    "# Correct typos in the 'Month' column\n",
    "water_quality_df['Month'] = water_quality_df['Month'].replace({\n",
    "    'Febuary': 'February',\n",
    "    'Aug': 'August',\n",
    "    'Sept': 'September',\n",
    "    'Nov': 'November',\n",
    "    'Dec': 'December'\n",
    "}, regex=False)  # Use regex=False to avoid treating the keys as regular expressions\n",
    "\n",
    "# Display the updated DataFrame to verify the changes\n",
    "\n",
    "# List of columns to exclude from transformation\n",
    "exclude_columns = ['Month', 'Wind', 'Condition']\n",
    "\n",
    "# Function to remove non-numeric characters from each cell\n",
    "def remove_non_numeric(value):\n",
    "    if isinstance(value, str) and value not in exclude_columns:\n",
    "        return re.sub(r'[^0-9.]', '', value)\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "# Apply the function to each cell in numeric columns of the dataframe\n",
    "for column in weather_df.columns:\n",
    "    if column not in exclude_columns:\n",
    "        weather_df[column] = weather_df[column].apply(remove_non_numeric)\n",
    "\n",
    "# Convert the numeric columns to numeric type\n",
    "numeric_columns = [col for col in weather_df.columns if col not in exclude_columns]\n",
    "weather_df[numeric_columns] = weather_df[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Define mappings for Wind column\n",
    "wind_mapping = {\n",
    "    'N': 1, 'NNE': 2, 'NE': 3, 'ENE': 4,\n",
    "    'E': 5, 'ESE': 6, 'SE': 7, 'SSE': 8,\n",
    "    'S': 9, 'SSW': 10, 'SW': 11, 'WSW': 12,\n",
    "    'W': 13, 'WNW': 14, 'NW': 15, 'NNW': 16,\n",
    "    'VAR': 17, 'CALM': 18\n",
    "}\n",
    "\n",
    "# Define mappings for Condition column\n",
    "condition_mapping = {\n",
    "    'Fair': 1, 'Mostly Cloudy': 2, 'Partly Cloudy': 3, 'Cloudy': 4,\n",
    "    'Light Rain': 5, 'Light Rain Shower': 6, 'Rain': 7, 'Heavy Rain': 8,\n",
    "    'Thunder': 9, 'Light Rain with Thunder': 10, 'T-Storm': 11,\n",
    "    'Heavy Rain Shower': 12, 'Rain Shower': 13, 'Showers in the Vicinity': 14,\n",
    "    'Thunder in the Vicinity': 15, 'Mostly Cloudy / Windy': 16,\n",
    "    'Fair / Windy': 17, 'Partly Cloudy / Windy': 18, 'Rain / Windy': 19,\n",
    "    'Light Rain Shower / Windy': 20, 'Heavy Rain / Windy': 21\n",
    "}\n",
    "\n",
    "# Apply mappings to Wind and Condition columns\n",
    "weather_df['Wind'] = weather_df['Wind'].map(wind_mapping)\n",
    "weather_df['Condition'] = weather_df['Condition'].map(condition_mapping)\n",
    "\n",
    "\n",
    "\n",
    "# Define a function to compute the mode\n",
    "def compute_mode(series):\n",
    "    return series.mode().iloc[0] if not series.mode().empty else None\n",
    "\n",
    "# Group by 'Year' and 'Month'\n",
    "grouped = weather_df.groupby(['Year', 'Month'])\n",
    "\n",
    "# Aggregate to get the mean for all columns except 'Wind' and 'Condition'\n",
    "# and the mode for 'Wind' and 'Condition'\n",
    "weather_monthly_stats = grouped.agg({\n",
    "    'Wind': compute_mode,\n",
    "    'Condition': compute_mode,\n",
    "    'Day': compute_mode,\n",
    "    'Time': 'mean',\n",
    "    'Temperature': 'mean',\n",
    "    'Dew Point' : 'mean',\n",
    "    'Humidity': 'mean',\n",
    "    'Wind Speed': 'mean',\n",
    "    'Wind Gust': 'mean',\n",
    "    'Pressure': 'mean',\n",
    "    'Precip.': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Print the result\n",
    "print(weather_monthly_stats)\n",
    "\n",
    "\n",
    "# Merge datasets on 'Month' and 'Year'\n",
    "merged_df = pd.merge(water_quality_df, weather_monthly_stats, on=['Month', 'Year'])\n",
    "\n",
    "print(merged_df['Month'].unique())\n",
    "\n",
    "# Step 8: Save the updated dataset\n",
    "output_file_path = '2023_Merged.csv'\n",
    "merged_df.to_csv(output_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b2ca181-cae8-40e4-8ae1-77479372a272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file with ISO-8859-1 encoding\n",
    "df = pd.read_csv('Overall-weather-dataset(csv_converted_2023).csv', encoding='iso-8859-1')\n",
    "\n",
    "# Write the CSV file with UTF-8 encoding\n",
    "df.to_csv('New_Weather.csv', encoding='utf-8', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8919808-032b-4abd-bfd4-721fb93456aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df2 = pd.read_csv('2023_Merged.csv')\n",
    "\n",
    "# Map month names to numbers\n",
    "month_mapping = {\n",
    "    'January': 1,\n",
    "    'February': 2,\n",
    "    'March': 3,\n",
    "    'April': 4,\n",
    "    'May': 5,\n",
    "    'June': 6,\n",
    "    'July': 7,\n",
    "    'August': 8,\n",
    "    'September': 9,\n",
    "    'October': 10,\n",
    "    'November': 11,\n",
    "    'December': 12\n",
    "}\n",
    "df2['Month'] = df2['Month'].map(month_mapping)\n",
    "\n",
    "# Convert 'Year', 'Month', 'Day' into a single 'Date' column\n",
    "df2['Date'] = pd.to_datetime(df2[['Year', 'Month', 'Day']])\n",
    "\n",
    "# Optionally, set 'Date' as the index if needed\n",
    "# df2.set_index('Date', inplace=True)\n",
    "\n",
    "# Save the DataFrame to a new CSV file\n",
    "df2.to_csv('Complete.csv', encoding='utf-8', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e59427-0143-458a-b684-31de7dbc6d33",
   "metadata": {},
   "source": [
    "Filling missing values with same month and weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b09bef8-9db7-4f9a-96f4-905df5d869ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('New_Merged.csv')\n",
    "\n",
    "# Columns of interest\n",
    "weather_cols = ['Temperature', 'Dew Point', 'Humidity', 'Wind', 'Wind Speed', \n",
    "                'Wind Gust', 'Pressure', 'Precip.', 'Condition']\n",
    "water_quality_cols = ['pH (units)', 'Ammonia (mg/L)', 'Nitrate (mg/L)', \n",
    "                      'Inorganic Phosphate (mg/L)', 'BOD (mg/l)', \n",
    "                      'Dissolved Oxygen (mg/l)', 'Total coliforms (MPN/100ml)']\n",
    "\n",
    "# Update the code to include \"Phytoplankton (cells/ml)\" in the comparison\n",
    "def phytoplankton_distance(row1, row2, threshold=0.1):\n",
    "    \"\"\"Calculate the distance between phytoplankton values, considering them close if within the threshold.\"\"\"\n",
    "    return abs(row1['Phytoplankton (cells/ml)'] - row2['Phytoplankton (cells/ml)']) <= threshold\n",
    "\n",
    "# Iterate over the rows with missing values in water quality columns\n",
    "for index, row in df[df[water_quality_cols].isnull().any(axis=1)].iterrows():\n",
    "    # Extract the month, year, and monitoring station of the row with missing values\n",
    "    month, year, station = row['Month'], row['Year'], row['Monitoring Stations']\n",
    "    \n",
    "    # Filter data for the same monitoring station and month in different years\n",
    "    similar_months = df[(df['Month'] == month) & (df['Year'] != year) & \n",
    "                        (df['Monitoring Stations'] == station) & \n",
    "                        (df['Phytoplankton (cells/ml)'].notnull())]\n",
    "    \n",
    "    # Compute similarity based on weather columns and phytoplankton\n",
    "    min_distance = float('inf')\n",
    "    best_match = None\n",
    "    \n",
    "    for i, other_row in similar_months.iterrows():\n",
    "        weather_distance = euclidean(row[weather_cols], other_row[weather_cols])\n",
    "        if phytoplankton_distance(row, other_row) and weather_distance < min_distance:\n",
    "            min_distance = weather_distance\n",
    "            best_match = other_row\n",
    "    \n",
    "    # If a best match is found, fill in the missing values\n",
    "    if best_match is not None:\n",
    "        for col in water_quality_cols:\n",
    "            if pd.isnull(row[col]):\n",
    "                df.at[index, col] = best_match[col]\n",
    "\n",
    "# Save the modified DataFrame\n",
    "output_path = 'Filled_Merged_Phytoplankton.csv'\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "94b505ce-624b-450d-9a39-ee03ac5a15a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Load your data into the DataFrame 'merged_df'\n",
    "merged_df = pd.read_csv('New_Merged.csv', encoding='utf-8')  # Replace with the correct file path and encoding\n",
    "\n",
    "#threshold = len(merged_df.columns) - 6\n",
    "#merged_df = merged_df.dropna(thresh=threshold)\n",
    "\n",
    "# Specify the columns to impute\n",
    "columns_to_impute = [\n",
    "    'pH (units)', \n",
    "    'Ammonia (mg/L)', \n",
    "    'Nitrate (mg/L)', \n",
    "    'Inorganic Phosphate (mg/L)', \n",
    "    'BOD (mg/l)', \n",
    "    'Dissolved Oxygen (mg/l)', \n",
    "    'Total coliforms (MPN/100ml)'\n",
    "]\n",
    "\n",
    "# Extract the columns to impute\n",
    "data_to_impute = merged_df[columns_to_impute]\n",
    "\n",
    "# Create the imputer\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "# Apply the imputer\n",
    "data_imputed = imputer.fit_transform(data_to_impute)\n",
    "\n",
    "# Convert the imputed data back to a DataFrame\n",
    "data_imputed_df = pd.DataFrame(data_imputed, columns=columns_to_impute)\n",
    "\n",
    "# Replace the original columns in the DataFrame with the imputed data\n",
    "merged_df[columns_to_impute] = data_imputed_df\n",
    "\n",
    "# Save the DataFrame with imputed values to a new CSV file\n",
    "merged_df.to_csv('New_Merged_Imputed.csv', index=False)  # Replace with your desired file path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f871cb14-9e61-41c6-b665-0c4cb34eec82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Monitoring Stations', 'Month', 'Year', 'pH (units)', 'Ammonia (mg/L)',\n",
      "       'Nitrate (mg/L)', 'Inorganic Phosphate (mg/L)', 'BOD (mg/l)',\n",
      "       'Dissolved Oxygen (mg/l)', 'Total coliforms (MPN/100ml)',\n",
      "       'Phytoplankton (cells/ml)', 'Wind', 'Condition', 'Day', 'Time',\n",
      "       'Temperature', 'Dew Point', 'Humidity', 'Wind Speed', 'Wind Gust',\n",
      "       'Pressure', 'Precip.', 'Date'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your data into the DataFrame 'merged_df'\n",
    "merged_df = pd.read_csv('New_Merged.csv', encoding='utf-8')  # Replace with the correct file path and encoding\n",
    "\n",
    "# Print the column names\n",
    "print(merged_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a988842-0753-4000-b021-2ce1a7f4f374",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the full dataset\n",
    "df = pd.read_csv('2023_merged.csv')\n",
    "\n",
    "# Filter the dataset to include only rows from the year 2023 for prediction\n",
    "df_2023 = df[df['Year'] == 2023]\n",
    "\n",
    "# Select the features used for prediction\n",
    "X_2023 = df_2023[['Temperature', 'Humidity', 'Wind', 'Wind Speed', 'Ammonia (mg/L)', 'Inorganic Phosphate (mg/L)', 'BOD (mg/l)']]\n",
    "\n",
    "# Load the saved model\n",
    "with open('xgb_model.pkl', 'rb') as file:\n",
    "    loaded_xgb_model = pickle.load(file)\n",
    "\n",
    "# Preprocess the data if necessary (e.g., scaling)\n",
    "\n",
    "# Load the scaler\n",
    "with open('xgb_scaler.pkl', 'rb') as file:\n",
    "    scaler = pickle.load(file)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_2023_scaled = scaler.fit_transform(X_2023)\n",
    "\n",
    "# Predict phytoplankton counts for 2023 data\n",
    "phytoplankton_predictions = loaded_xgb_model.predict(X_2023_scaled)\n",
    "\n",
    "# Add predictions to the 2023 dataframe\n",
    "df_2023['Predicted Phytoplankton (cells/ml)'] = phytoplankton_predictions\n",
    "\n",
    "# Merge the 2023 predictions back into the original dataset\n",
    "df_final = pd.merge(df, df_2023[['Year', 'Month', 'Day', 'Predicted Phytoplankton (cells/ml)']], \n",
    "                    on=['Year', 'Month', 'Day'], how='left')\n",
    "\n",
    "# Save the updated dataset with predictions to a new CSV file\n",
    "df_final.to_csv('final_dataset_with_predictions.csv', index=False)\n",
    "\n",
    "print(\"Final dataset saved to 'final_dataset_with_predictions.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a1ed4e5c-e174-41fb-9400-158890c1ba66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset with predictions updated and saved to 'updated_dataset_with_predictions.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the full dataset\n",
    "df = pd.read_csv('Complete.csv')\n",
    "\n",
    "# Filter the dataset to include only rows from the year 2023 for prediction\n",
    "df_2023 = df[df['Year'] == 2023]\n",
    "\n",
    "# Select the features used for prediction\n",
    "X_2023 = df_2023[['Temperature', 'Humidity', 'Wind', 'Wind Speed', 'Ammonia (mg/L)', 'Inorganic Phosphate (mg/L)', 'BOD (mg/l)']]\n",
    "\n",
    "# Load the saved model\n",
    "with open('xgb_model.pkl', 'rb') as file:\n",
    "    loaded_xgb_model = pickle.load(file)\n",
    "\n",
    "# Load the scaler\n",
    "with open('xgb_scaler.pkl', 'rb') as file:\n",
    "    scaler = pickle.load(file)\n",
    "\n",
    "# Scale the data using the loaded scaler\n",
    "X_2023_scaled = scaler.transform(X_2023)\n",
    "\n",
    "# Predict phytoplankton counts for 2023 data\n",
    "phytoplankton_predictions = loaded_xgb_model.predict(X_2023_scaled)\n",
    "\n",
    "# Round off the predictions to the nearest whole number\n",
    "phytoplankton_predictions = phytoplankton_predictions.round()\n",
    "\n",
    "# Update the 'Phytoplankton (cells/ml)' column with rounded predictions for 2023\n",
    "df.loc[df['Year'] == 2023, 'Phytoplankton (cells/ml)'] = phytoplankton_predictions\n",
    "\n",
    "# Save the updated dataset to a new CSV file\n",
    "df.to_csv('updated_dataset_with_predictions.csv', index=False)\n",
    "\n",
    "print(\"Dataset with predictions updated and saved to 'updated_dataset_with_predictions.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28148ee8-d3f8-45cb-9c09-7076e3dbca61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample input data (replace with realistic values)\n",
    "sample_data = pd.DataFrame({\n",
    "    'Temperature': [28.29166667],  # Example temperature\n",
    "    'Humidity': [65.91666667],     # Example humidity\n",
    "    'Wind': [6],            # Example wind direction (mapped value)\n",
    "    'Wind Speed': [10.58333333],   # Example wind speed\n",
    "    'Condition': [1],       # Example weather condition (mapped value)\n",
    "    'pH (units)': [8],    # Example pH level\n",
    "    'Ammonia (mg/L)': [0.057], # Example ammonia level\n",
    "    'Nitrate (mg/L)': [ 0.357], # Example nitrate level\n",
    "    'Inorganic Phosphate (mg/L)': [0.059], # Example phosphate level\n",
    "    'BOD (mg/l)': [2],    # Example BOD level\n",
    "    'Dissolved Oxygen (mg/l)': [7.9], # Example dissolved oxygen level\n",
    "    'Total coliforms (MPN/100ml)': [410] # Example total coliforms\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5b8d11-fde1-4833-84ae-90b4f07fb2c0",
   "metadata": {},
   "source": [
    "# Time Series Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fbcdc0de-a68e-4190-826d-eaab2e7526f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Monitoring Stations', 'Month', 'Year', 'Date', 'pH (units)',\n",
      "       'Ammonia (mg/L)', 'Inorganic Phosphate (mg/L)', 'BOD (mg/l)',\n",
      "       'Total coliforms (MPN/100ml)', 'Phytoplankton (cells/ml)'],\n",
      "      dtype='object')\n",
      "Monitoring Stations             12\n",
      "Month                           12\n",
      "Year                            12\n",
      "Date                            12\n",
      "pH (units)                     237\n",
      "Ammonia (mg/L)                 425\n",
      "Inorganic Phosphate (mg/L)     399\n",
      "BOD (mg/l)                     206\n",
      "Total coliforms (MPN/100ml)    229\n",
      "Phytoplankton (cells/ml)        58\n",
      "dtype: int64\n",
      "Monitoring Stations             0\n",
      "Month                           0\n",
      "Year                            0\n",
      "Date                            0\n",
      "pH (units)                      0\n",
      "Ammonia (mg/L)                  0\n",
      "Inorganic Phosphate (mg/L)      0\n",
      "BOD (mg/l)                      0\n",
      "Total coliforms (MPN/100ml)     0\n",
      "Phytoplankton (cells/ml)       46\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "df = pd.read_csv(\"updated_dataset_with_predictions.csv\")\n",
    "\n",
    "keep = ['Monitoring Stations', 'Month', 'Year', 'Date', 'pH (units)', 'Ammonia (mg/L)', 'Inorganic Phosphate (mg/L)', 'BOD (mg/l)', 'Total coliforms (MPN/100ml)', 'Phytoplankton (cells/ml)']\n",
    "\n",
    "df_dropped = df[keep]\n",
    "\n",
    "print(df_dropped.columns)\n",
    "\n",
    "missing = df_dropped.isnull().sum()\n",
    "\n",
    "print(missing)\n",
    "df_dropped.to_csv('dropped_columns.csv', index=False)\n",
    "\n",
    "drop = pd.read_csv('dropped_columns.csv')\n",
    "\n",
    "\n",
    "impute_columns = ['pH (units)', 'Ammonia (mg/L)', 'Inorganic Phosphate (mg/L)', 'BOD (mg/l)', 'Total coliforms (MPN/100ml)']\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "drop[impute_columns] = imputer.fit_transform(drop[impute_columns])\n",
    "\n",
    "drop = drop.dropna(subset=['Monitoring Stations'])\n",
    "\n",
    "\n",
    "missing2 = drop.isnull().sum()\n",
    "\n",
    "print(missing2)\n",
    "\n",
    "drop.to_csv('Knn_time.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89fa7eb4-3df9-4763-8eb8-316d6a81ec85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Monitoring Stations', 'Month', 'Year', 'Date', 'pH (units)',\n",
      "       'Ammonia (mg/L)', 'Inorganic Phosphate (mg/L)', 'BOD (mg/l)',\n",
      "       'Total coliforms (MPN/100ml)', 'Phytoplankton (cells/ml)'],\n",
      "      dtype='object')\n",
      "Monitoring Stations             12\n",
      "Month                           12\n",
      "Year                            12\n",
      "Date                            12\n",
      "pH (units)                     237\n",
      "Ammonia (mg/L)                 425\n",
      "Inorganic Phosphate (mg/L)     399\n",
      "BOD (mg/l)                     206\n",
      "Total coliforms (MPN/100ml)    229\n",
      "Phytoplankton (cells/ml)        58\n",
      "dtype: int64\n",
      "pH (units)                     0\n",
      "Ammonia (mg/L)                 0\n",
      "Inorganic Phosphate (mg/L)     0\n",
      "BOD (mg/l)                     0\n",
      "Total coliforms (MPN/100ml)    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "df = pd.read_csv(\"updated_dataset_with_predictions.csv\")\n",
    "\n",
    "keep = ['Monitoring Stations', 'Month', 'Year', 'Date', 'pH (units)', 'Ammonia (mg/L)', 'Inorganic Phosphate (mg/L)', 'BOD (mg/l)', 'Total coliforms (MPN/100ml)', 'Phytoplankton (cells/ml)']\n",
    "\n",
    "df_dropped = df[keep]\n",
    "\n",
    "print(df_dropped.columns)\n",
    "\n",
    "missing = df_dropped.isnull().sum()\n",
    "\n",
    "print(missing)\n",
    "df_dropped.to_csv('dropped_columns.csv', index=False)\n",
    "\n",
    "drop = pd.read_csv('dropped_columns.csv')\n",
    "\n",
    "\n",
    "# List of columns to fill based on their correlation with Phytoplankton (cells/ml)\n",
    "columns_to_fill = ['pH (units)', 'Ammonia (mg/L)', 'Inorganic Phosphate (mg/L)', 'BOD (mg/l)', 'Total coliforms (MPN/100ml)']\n",
    "\n",
    "# Define the predictors to be used\n",
    "predictors = ['Phytoplankton (cells/ml)']\n",
    "\n",
    "# Create a subset of the DataFrame including the predictors and the columns to fill\n",
    "df_subset = drop[predictors + columns_to_fill]\n",
    "\n",
    "# Initialize the MICE (Iterative Imputer)\n",
    "mice_imputer = IterativeImputer(max_iter=10, random_state=0)\n",
    "\n",
    "# Apply MICE imputation to the relevant subset of the DataFrame\n",
    "df_imputed = pd.DataFrame(mice_imputer.fit_transform(df_subset), columns=df_subset.columns)\n",
    "\n",
    "# Replace the original columns with the imputed ones\n",
    "drop[columns_to_fill] = df_imputed[columns_to_fill]\n",
    "\n",
    "# Check if missing values are filled\n",
    "print(drop[columns_to_fill].isnull().sum())\n",
    "\n",
    "# Save the updated dataset with imputed values to a new CSV file\n",
    "drop.to_csv('MICE_Time.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51da7df2-a57a-4772-af0b-f87f240fcc6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
